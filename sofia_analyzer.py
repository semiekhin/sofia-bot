#!/usr/bin/env python3
"""
Sofia Auto-Analyzer v2 â€” Ğ½Ğ¾Ñ‡Ğ½Ğ¾Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¼ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼
ĞŸĞµÑ€Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ¿ÑƒÑĞº: 22:00 11.12.2025
"""

import sqlite3
import json
import os
import shutil
from datetime import datetime, timedelta
from openai import OpenAI
import requests

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")  # Ğ¢Ğ¾ĞºĞµĞ½ Ğ±Ğ¾Ñ‚Ğ° Sofia
ADMIN_CHAT_ID = int(os.environ.get("ADMIN_CHAT_ID", "512319063"))  # Ğ¢Ğ²Ğ¾Ğ¹ chat_id

DB_PATH = "/opt/sofia-bot/sofia_conversations.db"
PROMPT_PATH = "/opt/sofia-bot/sofia_prompt.py"
BACKUP_DIR = "/opt/sofia-bot/backups"
LOGS_DIR = "/opt/sofia-bot/analyzer_logs"
LAST_ANALYSIS_FILE = "/opt/sofia-bot/last_analysis_time.txt"

# ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ Ğ¾Ñ†ĞµĞ½Ğ¾Ğº Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° (ÑÑ‚Ğ°Ğ²Ğ¸Ğ¼ 1 Ğ´Ğ»Ñ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ Ñ‚ĞµÑÑ‚Ğ°)
MIN_FEEDBACK_COUNT = 1

# ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°
ANALYZER_MODEL = "gpt-5.2"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ˜ĞĞ˜Ğ¦Ğ˜ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¿Ğ°Ğ¿ĞºĞ¸
os.makedirs(BACKUP_DIR, exist_ok=True)
os.makedirs(LOGS_DIR, exist_ok=True)

# Ğ£Ğ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ID Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°
RUN_ID = datetime.now().strftime("%Y%m%d_%H%M%S")
RUN_DIR = os.path.join(LOGS_DIR, RUN_ID)
os.makedirs(RUN_DIR, exist_ok=True)

client = None


def init_openai():
    """Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ OpenAI ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°"""
    global client
    if not OPENAI_API_KEY:
        raise ValueError("OPENAI_API_KEY Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½!")
    client = OpenAI(api_key=OPENAI_API_KEY)


def log(message, also_print=True):
    """Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ² Ñ„Ğ°Ğ¹Ğ» Ğ¸ ĞºĞ¾Ğ½ÑĞ¾Ğ»ÑŒ"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    line = f"[{timestamp}] {message}"
    
    if also_print:
        print(line)
    
    with open(os.path.join(RUN_DIR, "run.log"), "a", encoding="utf-8") as f:
        f.write(line + "\n")


def save_to_file(filename, content):
    """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ² Ñ„Ğ°Ğ¹Ğ» Ğ»Ğ¾Ğ³Ğ°"""
    path = os.path.join(RUN_DIR, filename)
    with open(path, "w", encoding="utf-8") as f:
        f.write(content)
    log(f"ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾: {filename}")
    return path


def send_telegram(message, parse_mode="HTML"):
    """ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ² Telegram"""
    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
        # Telegram Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ 4096 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²
        if len(message) > 4000:
            message = message[:4000] + "\n\n... (Ğ¾Ğ±Ñ€ĞµĞ·Ğ°Ğ½Ğ¾)"
        
        response = requests.post(url, json={
            "chat_id": ADMIN_CHAT_ID,
            "text": message,
            "parse_mode": parse_mode
        }, timeout=30)
        
        if response.status_code == 200:
            log("âœ… Telegram: ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾")
        else:
            log(f"âš ï¸ Telegram Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {response.text}")
    except Exception as e:
        log(f"âŒ Telegram exception: {e}")


def send_telegram_file(filepath, caption=""):
    """ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ² Telegram"""
    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendDocument"
        with open(filepath, "rb") as f:
            response = requests.post(url, 
                data={"chat_id": ADMIN_CHAT_ID, "caption": caption[:1024]},
                files={"document": f},
                timeout=60
            )
        if response.status_code == 200:
            log(f"âœ… Telegram: Ñ„Ğ°Ğ¹Ğ» {os.path.basename(filepath)} Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½")
        else:
            log(f"âš ï¸ Telegram file Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {response.text}")
    except Exception as e:
        log(f"âŒ Telegram file exception: {e}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¡Ğ‘ĞĞ  Ğ”ĞĞĞĞ«Ğ¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_last_analysis_time():
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ²Ñ€ĞµĞ¼Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°"""
    try:
        if os.path.exists(LAST_ANALYSIS_FILE):
            with open(LAST_ANALYSIS_FILE, 'r') as f:
                return f.read().strip()
    except:
        pass
    return None


def save_analysis_time():
    """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ²Ñ€ĞµĞ¼Ñ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    with open(LAST_ANALYSIS_FILE, 'w') as f:
        f.write(timestamp)
    log(f"ğŸ’¾ Ğ’Ñ€ĞµĞ¼Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾: {timestamp}")


def get_new_data():
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞĞĞ’Ğ«Ğ• Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    
    last_time = get_last_analysis_time()
    
    if last_time:
        log(f"ğŸ“… ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·: {last_time}")
        log(f"ğŸ“¥ Ğ‘ĞµÑ€Ñ‘Ğ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ ĞŸĞĞ¡Ğ›Ğ• {last_time}")
        
        # Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°
        c.execute('''
            SELECT chat_id, user_name, role, content, timestamp 
            FROM messages 
            WHERE timestamp > ?
            ORDER BY chat_id, timestamp
        ''', (last_time,))
        messages = c.fetchall()
        
        # Feedback Ğ¿Ğ¾ÑĞ»Ğµ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°
        c.execute('''
            SELECT expert_name, rating, comment, context, timestamp 
            FROM feedback_v2 
            WHERE timestamp > ?
            ORDER BY timestamp
        ''', (last_time,))
        feedback = c.fetchall()
    else:
        log("ğŸ“… ĞŸĞµÑ€Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ¿ÑƒÑĞº â€” Ğ±ĞµÑ€Ñ‘Ğ¼ Ğ’Ğ¡Ğ• Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ")
        
        # Ğ’ÑĞµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ
        c.execute('''
            SELECT chat_id, user_name, role, content, timestamp 
            FROM messages 
            ORDER BY chat_id, timestamp
        ''')
        messages = c.fetchall()
        
        # Ğ’ÑĞµ feedback
        c.execute('''
            SELECT expert_name, rating, comment, context, timestamp 
            FROM feedback_v2 
            ORDER BY timestamp
        ''')
        feedback = c.fetchall()
    
    conn.close()
    
    log(f"ğŸ“Š Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾: {len(messages)} ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹, {len(feedback)} Ğ¾Ñ†ĞµĞ½Ğ¾Ğº")
    return messages, feedback


def format_dialogs(messages):
    """Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ¸"""
    if not messages:
        return "ĞĞµÑ‚ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²."
    
    dialogs = {}
    for chat_id, user_name, role, content, timestamp in messages:
        if chat_id not in dialogs:
            dialogs[chat_id] = {"user": user_name or "Unknown", "messages": []}
        dialogs[chat_id]["messages"].append({
            "role": role,
            "content": content,
            "time": timestamp
        })
    
    result = []
    for chat_id, data in dialogs.items():
        result.append(f"\n{'='*50}")
        result.append(f"Ğ”Ğ˜ĞĞ›ĞĞ“ Ğ¡: {data['user']} (chat_id: {chat_id})")
        result.append('='*50)
        for m in data["messages"]:
            role = "ğŸ¤– Ğ¡ĞĞ¤Ğ˜Ğ¯" if m["role"] == "assistant" else "ğŸ‘¤ ĞšĞ›Ğ˜Ğ•ĞĞ¢"
            result.append(f"[{m['time']}] {role}:")
            result.append(f"   {m['content']}")
            result.append("")
    
    return "\n".join(result)


def format_feedback(feedback):
    """Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¾Ñ†ĞµĞ½ĞºĞ¸"""
    if not feedback:
        return "ĞĞµÑ‚ Ğ¾Ñ†ĞµĞ½Ğ¾Ğº ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ²."
    
    result = []
    for expert, rating, comment, context, timestamp in feedback:
        emoji = "âœ… GOOD" if rating == "good" else "âŒ BAD"
        result.append(f"\n{'â”€'*50}")
        result.append(f"{emoji} | Ğ­ĞºÑĞ¿ĞµÑ€Ñ‚: {expert} | {timestamp}")
        result.append('â”€'*50)
        
        if comment:
            result.append(f"ğŸ’¬ ĞšĞĞœĞœĞ•ĞĞ¢ĞĞ Ğ˜Ğ™: {comment}")
        
        # ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ°
        try:
            ctx = json.loads(context)
            result.append("\nğŸ“ ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ°:")
            for m in ctx:
                role = "Ğ¡Ğ¾Ñ„Ğ¸Ñ" if m["role"] == "assistant" else "ĞšĞ»Ğ¸ĞµĞ½Ñ‚"
                content = m["content"][:150] + "..." if len(m["content"]) > 150 else m["content"]
                result.append(f"   {role}: {content}")
        except:
            pass
        
        result.append("")
    
    return "\n".join(result)


def get_current_prompt():
    """Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚"""
    with open(PROMPT_PATH, "r", encoding="utf-8") as f:
        return f.read()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞĞĞĞ›Ğ˜Ğ— GPT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def build_analysis_prompt(dialogs_text, feedback_text, current_prompt):
    """Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°"""
    
    return f"""Ğ¢Ñ‹ â€” ÑĞºÑĞ¿ĞµÑ€Ñ‚ Ğ¿Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ°Ğ¼ Ğ½ĞµĞ´Ğ²Ğ¸Ğ¶Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚-Ğ¸Ğ½Ğ¶ĞµĞ½ĞµÑ€.

Ğ¢Ğ²Ğ¾Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°: Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ¸ AI-Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ½Ğ¸ĞºĞ° "Ğ¡Ğ¾Ñ„Ğ¸Ñ" Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ÑŒ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ² Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Ğ”Ğ˜ĞĞ›ĞĞ“Ğ˜
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{dialogs_text}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ĞĞ¦Ğ•ĞĞšĞ˜ Ğ­ĞšĞ¡ĞŸĞ•Ğ Ğ¢ĞĞ’ (Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€Ğ¾Ğ² Ğ¿Ğ¾ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ°Ğ¼)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{feedback_text}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Ğ¢Ğ•ĞšĞ£Ğ©Ğ˜Ğ™ ĞŸĞ ĞĞœĞŸĞ¢ Ğ¡ĞĞ¤Ğ˜Ğ˜
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```python
{current_prompt}
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Ğ¢Ğ’ĞĞ¯ Ğ—ĞĞ”ĞĞ§Ğ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. **Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ**: Ğ¡ĞºĞ¾Ğ»ÑŒĞºĞ¾ GOOD, ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ BAD, Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚ ÑƒÑĞ¿ĞµÑ…Ğ°

2. **Ğ§Ğ¢Ğ Ğ ĞĞ‘ĞĞ¢ĞĞ•Ğ¢**: Ğ’Ñ‹Ğ´ĞµĞ»Ğ¸ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ğ»Ğ¸ GOOD Ğ¾Ñ†ĞµĞ½ĞºĞ¸

3. **ĞŸĞ ĞĞ‘Ğ›Ğ•ĞœĞ«**: Ğ’Ñ‹Ğ´ĞµĞ»Ğ¸ 2-3 Ğ³Ğ»Ğ°Ğ²Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¸Ğ· BAD Ğ¾Ñ†ĞµĞ½Ğ¾Ğº. ĞŸÑ€Ğ¾Ñ†Ğ¸Ñ‚Ğ¸Ñ€ÑƒĞ¹ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ².

4. **Ğ Ğ•Ğ¨Ğ•ĞĞ˜Ğ¯**: Ğ”Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ:
   - ĞšĞ°ĞºÑƒÑ Ñ„Ñ€Ğ°Ğ·Ñƒ/Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ
   - Ğ’ ĞºĞ°ĞºÑƒÑ ÑĞµĞºÑ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ°
   - ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ ĞºĞ°Ğº ÑÑ‚Ğ¾ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ¾ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ

5. **ĞĞĞ’Ğ«Ğ™ ĞŸĞ ĞĞœĞŸĞ¢**: Ğ’Ñ‹Ğ´Ğ°Ğ¹ ĞŸĞĞ›ĞĞ«Ğ™ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»Ñ‘Ğ½Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ» sofia_prompt.py
   - Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒ Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¹: # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¾: {datetime.now().strftime("%Y-%m-%d")} Ğ°Ğ²Ñ‚Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ¼
   - Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸ Ğ’Ğ¡Ğ® ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸
   - Ğ’Ğ½ĞµÑĞ¸ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ BAD ĞºĞµĞ¹ÑĞ¾Ğ²
   - ĞĞ• ÑƒĞ´Ğ°Ğ»ÑĞ¹ Ñ‚Ğ¾ Ñ‡Ñ‚Ğ¾ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ (GOOD)

Ğ’ĞĞ–ĞĞ: 
- ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ‚Ğ¾Ñ‡ĞµÑ‡Ğ½Ñ‹Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ
- ĞšĞ°Ğ¶Ğ´Ğ¾Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ¾ Ñ€ĞµÑˆĞ°Ñ‚ÑŒ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½ÑƒÑ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ Ğ¸Ğ· BAD
- Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸ Ğ²ĞµÑÑŒ Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğ¹ ĞºĞ¾Ğ´

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Ğ¤ĞĞ ĞœĞĞ¢ ĞĞ¢Ğ’Ğ•Ğ¢Ğ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## ğŸ“Š Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ
(Ñ†Ğ¸Ñ„Ñ€Ñ‹)

## âœ… Ğ§Ğ¢Ğ Ğ ĞĞ‘ĞĞ¢ĞĞ•Ğ¢
(ÑĞ¿Ğ¸ÑĞ¾Ğº)

## âŒ ĞŸĞ ĞĞ‘Ğ›Ğ•ĞœĞ«
(ÑĞ¿Ğ¸ÑĞ¾Ğº Ñ Ñ†Ğ¸Ñ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ²)

## ğŸ’¡ Ğ Ğ•Ğ¨Ğ•ĞĞ˜Ğ¯
(ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ)

## ğŸ“ ĞĞĞ’Ğ«Ğ™ ĞŸĞ ĞĞœĞŸĞ¢
```python
(Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ´ Ñ„Ğ°Ğ¹Ğ»Ğ° sofia_prompt.py)
```
"""


def call_gpt_analysis(analysis_prompt):
    """ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ½Ğ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·"""
    log(f"ğŸ§  ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ² {ANALYZER_MODEL}...")
    log(f"   Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°: ~{len(analysis_prompt)} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²")
    
    try:
        response = client.responses.create(
            model=ANALYZER_MODEL,
            input=analysis_prompt,
            
        )
        
        result = response.output_text
        log(f"âœ… ĞÑ‚Ğ²ĞµÑ‚ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½: ~{len(result)} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²")
        return result
        
    except Exception as e:
        log(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° API: {e}")
        return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def extract_new_prompt(analysis_result):
    """Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ¸Ğ· Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°"""
    if not analysis_result:
        return None
    
    import re
    
    # Ğ˜Ñ‰ĞµĞ¼ ĞºĞ¾Ğ´ Ğ¼ĞµĞ¶Ğ´Ñƒ ```python Ğ¸ ```
    matches = re.findall(r'```python\n(.*?)```', analysis_result, re.DOTALL)
    
    if matches:
        # Ğ˜Ñ‰ĞµĞ¼ Ñ‚Ğ¾Ñ‚ ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ½ÑƒĞ¶Ğ½Ñ‹Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸
        for match in reversed(matches):
            if "def get_system_prompt" in match and "def get_time_context" in match:
                log(f"âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚: {len(match)} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²")
                return match
    
    log("âš ï¸ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ¸Ğ· Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°")
    return None


def extract_analysis_summary(analysis_result):
    """Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ ĞºÑ€Ğ°Ñ‚ĞºÑƒÑ ÑĞ²Ğ¾Ğ´ĞºÑƒ Ğ´Ğ»Ñ Telegram"""
    if not analysis_result:
        return "ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ½Ğµ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½"
    
    # Ğ‘ĞµÑ€Ñ‘Ğ¼ Ğ²ÑÑ‘ Ğ´Ğ¾ "## ğŸ“ ĞĞĞ’Ğ«Ğ™ ĞŸĞ ĞĞœĞŸĞ¢"
    parts = analysis_result.split("## ğŸ“ ĞĞĞ’Ğ«Ğ™ ĞŸĞ ĞĞœĞŸĞ¢")
    if len(parts) > 1:
        return parts[0].strip()
    
    # Ğ˜Ğ»Ğ¸ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 2000 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²
    return analysis_result[:2000]


def validate_prompt(new_prompt):
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ğ¾ÑÑ‚ÑŒ Python"""
    try:
        compile(new_prompt, '<string>', 'exec')
        
        if "def get_system_prompt" not in new_prompt:
            return False, "ĞĞµÑ‚ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ get_system_prompt"
        if "def get_time_context" not in new_prompt:
            return False, "ĞĞµÑ‚ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ get_time_context"
        if "COMPANY" not in new_prompt:
            return False, "ĞĞµÑ‚ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ COMPANY"
            
        return True, "OK"
    except SyntaxError as e:
        return False, f"Ğ¡Ğ¸Ğ½Ñ‚Ğ°ĞºÑĞ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {e}"


def backup_current_prompt():
    """Ğ‘ÑĞºĞ°Ğ¿ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ°"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_path = os.path.join(BACKUP_DIR, f"sofia_prompt_{timestamp}.py")
    shutil.copy(PROMPT_PATH, backup_path)
    log(f"ğŸ’¾ Ğ‘ÑĞºĞ°Ğ¿ ÑĞ¾Ğ·Ğ´Ğ°Ğ½: {backup_path}")
    
    # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ ÑÑ‚Ğ°Ñ€Ñ‹Ğµ (Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ¼ 7)
    backups = sorted([f for f in os.listdir(BACKUP_DIR) if f.endswith('.py')])
    while len(backups) > 7:
        old = backups.pop(0)
        os.remove(os.path.join(BACKUP_DIR, old))
        log(f"ğŸ—‘ï¸ Ğ£Ğ´Ğ°Ğ»Ñ‘Ğ½ ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ Ğ±ÑĞºĞ°Ğ¿: {old}")
    
    return backup_path


def apply_new_prompt(new_prompt):
    """ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚"""
    with open(PROMPT_PATH, "w", encoding="utf-8") as f:
        f.write(new_prompt)
    log("âœ… ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ·Ğ°Ğ¿Ğ¸ÑĞ°Ğ½")


def restart_bot():
    """ĞŸĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑĞº Ğ±Ğ¾Ñ‚Ğ°"""
    log("ğŸ”„ ĞŸĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ sofia-bot...")
    result = os.system("systemctl restart sofia-bot")
    if result == 0:
        log("âœ… Ğ‘Ğ¾Ñ‚ Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½")
    else:
        log(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑĞºĞ°: ĞºĞ¾Ğ´ {result}")
    return result == 0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ“Ğ›ĞĞ’ĞĞĞ¯ Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    log("=" * 60)
    log("ğŸš€ SOFIA AUTO-ANALYZER Ğ—ĞĞŸĞ£Ğ©Ğ•Ğ")
    log(f"   Run ID: {RUN_ID}")
    log(f"   Ğ›Ğ¾Ğ³Ğ¸: {RUN_DIR}")
    log("=" * 60)
    
    send_telegram(f"ğŸš€ <b>ĞĞ²Ñ‚Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½</b>\n\nRun ID: {RUN_ID}")
    
    try:
        # 1. Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
        log("\n[1/8] Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ OpenAI...")
        init_openai()
        log("âœ… OpenAI ĞºĞ»Ğ¸ĞµĞ½Ñ‚ Ğ³Ğ¾Ñ‚Ğ¾Ğ²")
        
        # 2. Ğ¡Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
        log("\n[2/8] Ğ¡Ğ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· Ğ±Ğ°Ğ·Ñ‹...")
        messages, feedback = get_new_data()
        
        if len(feedback) < MIN_FEEDBACK_COUNT:
            msg = f"â¸ï¸ ĞĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ¾Ñ†ĞµĞ½Ğ¾Ğº: {len(feedback)} < {MIN_FEEDBACK_COUNT}"
            log(msg)
            send_telegram(msg)
            return
        
        # 3. Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
        log("\n[3/8] Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…...")
        dialogs_text = format_dialogs(messages)
        feedback_text = format_feedback(feedback)
        current_prompt = get_current_prompt()
        
        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
        save_to_file("01_dialogs.txt", dialogs_text)
        save_to_file("02_feedback.txt", feedback_text)
        save_to_file("03_current_prompt.py", current_prompt)
        
        # 4. Ğ¡Ğ±Ğ¾Ñ€ĞºĞ° Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ° Ğ´Ğ»Ñ GPT
        log("\n[4/8] Ğ¡Ğ±Ğ¾Ñ€ĞºĞ° Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ° Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°...")
        analysis_prompt = build_analysis_prompt(dialogs_text, feedback_text, current_prompt)
        save_to_file("04_gpt_input.txt", analysis_prompt)
        log(f"   Ğ Ğ°Ğ·Ğ¼ĞµÑ€: {len(analysis_prompt)} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² (~{len(analysis_prompt)//4} Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²)")
        
        # 5. ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ² GPT
        log("\n[5/8] ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ² GPT-5.1...")
        analysis_result = call_gpt_analysis(analysis_prompt)
        
        if not analysis_result:
            send_telegram("âŒ <b>ĞÑˆĞ¸Ğ±ĞºĞ°</b>: GPT Ğ½Ğµ Ğ²ĞµÑ€Ğ½ÑƒĞ» Ğ¾Ñ‚Ğ²ĞµÑ‚")
            return
        
        save_to_file("05_gpt_output.txt", analysis_result)
        
        # 6. Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ°
        log("\n[6/8] Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ°...")
        new_prompt = extract_new_prompt(analysis_result)
        analysis_summary = extract_analysis_summary(analysis_result)
        
        if not new_prompt:
            log("âš ï¸ ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ½Ğµ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡Ñ‘Ğ½ â€” ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ»Ñ Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€Ğ°")
            send_telegram(f"âš ï¸ <b>ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½, Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ½Ğµ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡Ñ‘Ğ½</b>\n\nĞ¡Ğ¼Ğ¾Ñ‚Ñ€Ğ¸ Ğ»Ğ¾Ğ³Ğ¸: {RUN_DIR}")
            send_telegram_file(os.path.join(RUN_DIR, "05_gpt_output.txt"), "ĞÑ‚Ğ²ĞµÑ‚ GPT")
            return
        
        save_to_file("06_new_prompt.py", new_prompt)
        
        # 7. Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ
        log("\n[7/8] Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ°...")
        valid, error = validate_prompt(new_prompt)
        
        if not valid:
            log(f"âŒ ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ½ĞµĞ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹: {error}")
            send_telegram(f"âŒ <b>ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ½ĞµĞ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹</b>\n\nĞÑˆĞ¸Ğ±ĞºĞ°: {error}\n\nĞ¡Ğ¼Ğ¾Ñ‚Ñ€Ğ¸ Ğ»Ğ¾Ğ³Ğ¸: {RUN_DIR}")
            send_telegram_file(os.path.join(RUN_DIR, "06_new_prompt.py"), "ĞĞµĞ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚")
            return
        
        log("âœ… ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹")
        
        # 8. ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ
        log("\n[8/8] ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹...")
        backup_path = backup_current_prompt()
        apply_new_prompt(new_prompt)
        bot_restarted = restart_bot()
        
        # Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ
        log("\n" + "=" * 60)
        log("âœ… ĞĞ’Ğ¢ĞĞĞĞĞ›Ğ˜Ğ— Ğ—ĞĞ’Ğ•Ğ Ğ¨ĞĞ Ğ£Ğ¡ĞŸĞ•Ğ¨ĞĞ")
        log("=" * 60)
        
        # ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑĞ²Ğ¾Ğ´ĞºÑƒ
        final_message = f"""âœ… <b>ĞĞ’Ğ¢ĞĞĞĞĞ›Ğ˜Ğ— Ğ—ĞĞ’Ğ•Ğ Ğ¨ĞĞ</b>

ğŸ“Š <b>Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ:</b>
â€¢ Ğ”Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ²: {len(set(m[0] for m in messages))}
â€¢ Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹: {len(messages)}
â€¢ ĞÑ†ĞµĞ½Ğ¾Ğº: {len(feedback)}

ğŸ’¾ <b>Ğ¤Ğ°Ğ¹Ğ»Ñ‹:</b>
â€¢ Ğ‘ÑĞºĞ°Ğ¿: ÑĞ¾Ğ·Ğ´Ğ°Ğ½
â€¢ ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚: Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½Ñ‘Ğ½
â€¢ Ğ‘Ğ¾Ñ‚: {'âœ… Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½' if bot_restarted else 'âš ï¸ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ñ€ÑƒÑ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑĞºĞ°'}

ğŸ“ <b>Ğ›Ğ¾Ğ³Ğ¸:</b> {RUN_DIR}

{'â”€'*30}
{analysis_summary[:1500]}..."""
        
        send_telegram(final_message)
        
        # ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ„Ğ°Ğ¹Ğ»Ñ‹
        send_telegram_file(os.path.join(RUN_DIR, "05_gpt_output.txt"), "ğŸ“„ ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ GPT")
        send_telegram_file(os.path.join(RUN_DIR, "06_new_prompt.py"), "ğŸ“„ ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚")
        
    except Exception as e:
        error_msg = f"âŒ <b>ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞĞ¯ ĞĞ¨Ğ˜Ğ‘ĞšĞ</b>\n\n{type(e).__name__}: {e}"
        log(f"âŒ ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞĞ¯ ĞĞ¨Ğ˜Ğ‘ĞšĞ: {e}")
        send_telegram(error_msg)
        
        import traceback
        save_to_file("ERROR.txt", traceback.format_exc())


if __name__ == "__main__":
    main()
