# sofia_hybrid.py ‚Äî v2.1
from sofia_prompt import get_system_prompt
# –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: —É–±—Ä–∞–Ω—ã temperature/top_p –¥–ª—è gpt-5.2 (responses API)
from detectors import *

from openai import OpenAI
import re
import os

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

MODEL_MODE = os.getenv("MODEL_MODE", "gpt-5.2")

MODEL_CONFIGS = {
    "gpt-4o": {
        "model": "gpt-4o",
        "use_responses_api": False,
        "temperature": 0.4,
        "max_tokens": 200,
        "reasoning": None
    },
    "gpt-5.2": {
        "model": "gpt-5.2",
        "use_responses_api": True,
        "max_tokens": 400,
        "reasoning": None
    },
    "gpt-5.2-reasoning": {
        "model": "gpt-5.2",
        "use_responses_api": True,
        "max_tokens": 400,
        "reasoning": {"effort": "xhigh"}
    }
}

def get_model_config():
    return MODEL_CONFIGS.get(MODEL_MODE, MODEL_CONFIGS["gpt-5.2"])

SYSTEM_PROMPT = """
–¢—ã ‚Äî –°–æ—Ñ–∏—è, –º–µ–Ω–µ–¥–∂–µ—Ä –æ—Ç–¥–µ–ª–∞ –ø—Ä–æ–¥–∞–∂ Oazis Estate (–∫—É—Ä–æ—Ä—Ç–Ω–∞—è –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å –≤ –†–æ—Å—Å–∏–∏).

–°–¢–ò–õ–¨:
‚Äî –ü–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–æ: 1-3 —Å—Ç—Ä–æ–∫–∏
‚Äî –ö–∞–∫ –∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫ –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–µ
‚Äî –≠–º–æ–¥–∑–∏: 0-1 –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ
‚Äî –û–±—Ä–∞—â–∞–π—Å—è –Ω–∞ "–í—ã"

–¢–ï–†–ú–ò–ù–û–õ–û–ì–ò–Ø:
‚Äî –ì–æ–≤–æ—Ä–∏ "–∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è", –Ω–µ "—Ä–æ—Å—Ç —Ü–µ–Ω—ã"  
‚Äî –¶–µ–Ω—ã –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º: "6‚Äì12 –º–ª–Ω", –Ω–µ "–æ—Ç 6 –º–ª–Ω"
‚Äî –ù–µ –Ω–∞–∑—ã–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ñ–ö –¥–æ –≤—ã—è—Å–Ω–µ–Ω–∏—è –±—é–¥–∂–µ—Ç–∞

–°–ü–†–ê–í–û–ß–ù–ò–ö –¶–ï–ù:
‚Äî –°–æ—á–∏ –∫–æ–º—Ñ–æ—Ä—Ç: 6‚Äì12 –º–ª–Ω
‚Äî –°–æ—á–∏ –±–∏–∑–Ω–µ—Å: 12‚Äì25 –º–ª–Ω
‚Äî –ê–Ω–∞–ø–∞: 9‚Äì15 –º–ª–Ω
‚Äî –ö—Ä—ã–º: 9.5‚Äì18 –º–ª–Ω
‚Äî –ö—Ä–∞—Å–Ω–∞—è –ü–æ–ª—è–Ω–∞: 19‚Äì35 –º–ª–Ω
‚Äî –ê–ª—Ç–∞–π: 14.5‚Äì22 –º–ª–Ω
‚Äî –ò–ø–æ—Ç–µ–∫–∞: –æ—Ç 8% –≥–æ–¥–æ–≤—ã—Ö

–¶–ï–õ–¨ –†–ê–ó–ì–û–í–û–†–ê:
‚Äî –ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è: —Ü–µ–ª—å –ø–æ–∫—É–ø–∫–∏, –ª–æ–∫–∞—Ü–∏—è, –±—é–¥–∂–µ—Ç, —Å–ø–æ—Å–æ–± –æ–ø–ª–∞—Ç—ã
‚Äî –ì–ª–∞–≤–Ω–∞—è —Ü–µ–ª—å: –Ω–∞–∑–Ω–∞—á–∏—Ç—å —Å–æ–∑–≤–æ–Ω/–≤–∏–¥–µ–æ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é –Ω–∞ 15 –º–∏–Ω—É—Ç
‚Äî –û—Ç–ø—Ä–∞–≤–∫–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤: —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –æ—Ç–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –æ—Ç —Å–æ–∑–≤–æ–Ω–∞
"""

def is_send_request(text: str) -> bool:
    text_lower = text.lower()
    return any(p in text_lower for p in SEND_PATTERNS)


def is_call_rejection(text: str) -> bool:
    text_lower = text.lower()
    return any(p in text_lower for p in CALL_REJECT_PATTERNS)


def is_call_agreement(text: str) -> bool:
    text_lower = text.lower()
    has_agree = any(p in text_lower for p in CALL_AGREE_PATTERNS)
    has_reject = any(p in text_lower for p in CALL_REJECT_PATTERNS)
    return has_agree and not has_reject


def is_neutral_answer(text: str) -> bool:
    text_lower = text.lower()
    return any(p in text_lower for p in NEUTRAL_PATTERNS)


def is_irritated(text: str) -> bool:
    text_lower = text.lower()
    return any(p in text_lower for p in IRRITATED_PATTERNS)


def has_question(text: str) -> bool:
    return "?" in text


def remove_question(text: str) -> str:
    sentences = re.split(r'(?<=[.!?])\s+', text.strip())
    result = [s for s in sentences if "?" not in s]
    if result:
        return " ".join(result)
    else:
        return sentences[0].replace("?", ".") if sentences else text


def analyze_history(history: list) -> dict:
    stats = {
        "total_messages": len(history),
        "user_messages": 0,
        "bot_messages": 0,
        "send_requests": 0,
        "call_rejections": 0,
        "call_agreements": 0,
        "neutral_answers": 0,
        "irritation_detected": False,
        "questions_after_last_send": 0,
        "last_send_request_index": -1,
        "call_offered": False
    }
    
    for i, msg in enumerate(history):
        role = msg.get("role", "")
        content = msg.get("content", "")
        
        if role == "user":
            stats["user_messages"] += 1
            if is_send_request(content):
                stats["send_requests"] += 1
                stats["last_send_request_index"] = i
            if is_call_rejection(content):
                stats["call_rejections"] += 1
            if is_call_agreement(content):
                stats["call_agreements"] += 1
            if is_neutral_answer(content):
                stats["neutral_answers"] += 1
            if is_irritated(content):
                stats["irritation_detected"] = True
        elif role == "assistant":
            stats["bot_messages"] += 1
            if "—Å–æ–∑–≤–æ–Ω" in content.lower() or "–≤–∏–¥–µ–æ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü" in content.lower():
                stats["call_offered"] = True
    
    if stats["last_send_request_index"] >= 0:
        for msg in history[stats["last_send_request_index"] + 1:]:
            if msg.get("role") == "assistant" and has_question(msg.get("content", "")):
                stats["questions_after_last_send"] += 1
    
    return stats


MAX_MESSAGES = 14
MAX_QUESTIONS_AFTER_SEND = 1
MAX_CALL_REJECTIONS = 2
MAX_NEUTRAL_ANSWERS = 3


def decide_action(stats: dict, last_message: str) -> dict:
    current_is_send = is_send_request(last_message)
    current_is_irritated = is_irritated(last_message)
    current_is_rejection = is_call_rejection(last_message)
    current_is_agreement = is_call_agreement(last_message)
    current_is_neutral = is_neutral_answer(last_message)
    
    if current_is_agreement:
        return {
            "action": "CONFIRM_CALL",
            "allow_questions": True,
            "reason": "call_agreed",
            "instruction": "–ö–ª–∏–µ–Ω—Ç —Å–æ–≥–ª–∞—Å–∏–ª—Å—è –Ω–∞ —Å–æ–∑–≤–æ–Ω! –ü–æ–¥—Ç–≤–µ—Ä–¥–∏ –≤—Ä–µ–º—è. –ú–æ–∂–µ—à—å —Å–ø—Ä–æ—Å–∏—Ç—å: '–†–µ—à–µ–Ω–∏–µ —Å–∞–º–∏ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç–µ –∏–ª–∏ —Å –∫–µ–º-—Ç–æ?'"
        }
    
    if current_is_irritated or stats["irritation_detected"]:
        return {
            "action": "SEND_MATERIALS",
            "allow_questions": False,
            "reason": "irritated",
            "instruction": "–ö–ª–∏–µ–Ω—Ç —Ä–∞–∑–¥—Ä–∞–∂—ë–Ω. –ò–∑–≤–∏–Ω–∏—Å—å –∫–æ—Ä–æ—Ç–∫–æ –∏ —Å–∫–∞–∂–∏ —á—Ç–æ –ø—Ä–∏—à–ª—ë—à—å 2-3 –≤–∞—Ä–∏–∞–Ω—Ç–∞. –ë–ï–ó –í–û–ü–†–û–°–û–í. –ù–∏–∫–∞–∫–∏—Ö."
        }
    
    if stats["send_requests"] >= 2 or (stats["send_requests"] >= 1 and current_is_send):
        return {
            "action": "SEND_MATERIALS",
            "allow_questions": False,
            "reason": "multiple_send_requests",
            "instruction": "–ö–ª–∏–µ–Ω—Ç —É–∂–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø—Ä–æ—Å–∏–ª —Å–∫–∏–Ω—É—Ç—å. –•–≤–∞—Ç–∏—Ç. –°–∫–∞–∂–∏ —á—Ç–æ –ø—Ä–∏—à–ª—ë—à—å 2-3 –≤–∞—Ä–∏–∞–Ω—Ç–∞. –ë–ï–ó –í–û–ü–†–û–°–û–í."
        }
    
    if stats["questions_after_last_send"] >= MAX_QUESTIONS_AFTER_SEND and current_is_send:
        return {
            "action": "SEND_MATERIALS",
            "allow_questions": False,
            "reason": "asked_after_send",
            "instruction": "–ö–ª–∏–µ–Ω—Ç –ø—Ä–æ—Å–∏–ª —Å–∫–∏–Ω—É—Ç—å, –º—ã –∑–∞–¥–∞–ª–∏ –≤–æ–ø—Ä–æ—Å, –æ–Ω —Å–Ω–æ–≤–∞ –ø—Ä–æ—Å–∏—Ç. –•–≤–∞—Ç–∏—Ç. –°–∫–∞–∂–∏ —á—Ç–æ –ø—Ä–∏—à–ª—ë—à—å. –ë–ï–ó –í–û–ü–†–û–°–û–í."
        }
    
    if stats["total_messages"] >= MAX_MESSAGES:
        return {
            "action": "SEND_MATERIALS",
            "allow_questions": False,
            "reason": "too_long",
            "instruction": "–î–∏–∞–ª–æ–≥ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π. –ó–∞–∫–∞–Ω—á–∏–≤–∞–µ–º. –°–∫–∞–∂–∏ —á—Ç–æ –ø—Ä–∏—à–ª—ë—à—å –≤–∞—Ä–∏–∞–Ω—Ç—ã. –ë–ï–ó –õ–ò–®–ù–ò–• –í–û–ü–†–û–°–û–í."
        }
    
    total_rejections = stats["call_rejections"] + (1 if current_is_rejection else 0)
    if total_rejections >= MAX_CALL_REJECTIONS:
        return {
            "action": "SEND_MATERIALS",
            "allow_questions": False,
            "reason": "call_rejected_twice",
            "instruction": "–ö–ª–∏–µ–Ω—Ç —É–∂–µ –æ—Ç–∫–∞–∑—ã–≤–∞–ª—Å—è –æ—Ç —Å–æ–∑–≤–æ–Ω–∞. –ù–µ –Ω–∞—Å—Ç–∞–∏–≤–∞–π. –°–∫–∞–∂–∏ —á—Ç–æ –ø—Ä–∏—à–ª—ë—à—å 2-3 –≤–∞—Ä–∏–∞–Ω—Ç–∞. –ë–ï–ó –í–û–ü–†–û–°–û–í."
        }
    
    total_neutral = stats["neutral_answers"] + (1 if current_is_neutral else 0)
    if total_neutral >= MAX_NEUTRAL_ANSWERS:
        return {
            "action": "SEND_MATERIALS",
            "allow_questions": False,
            "reason": "too_many_neutral",
            "instruction": "–ö–ª–∏–µ–Ω—Ç –º–Ω–æ–≥–æ —Ä–∞–∑ –æ—Ç–≤–µ—á–∞–ª '–±–µ–∑ —Ä–∞–∑–Ω–∏—Ü—ã'. –•–≤–∞—Ç–∏—Ç —Å–ø—Ä–∞—à–∏–≤–∞—Ç—å. –°–∫–∞–∂–∏ —á—Ç–æ –ø—Ä–∏—à–ª—ë—à—å –≤–∞—Ä–∏–∞–Ω—Ç—ã. –ë–ï–ó –í–û–ü–†–û–°–û–í."
        }
    
    if current_is_send and stats["questions_after_last_send"] == 0:
        return {
            "action": "QUALIFY_THEN_SEND",
            "allow_questions": True,
            "reason": "first_send_request",
            "instruction": "–ö–ª–∏–µ–Ω—Ç –ø—Ä–æ—Å–∏—Ç —Å–∫–∏–Ω—É—Ç—å. –ü–æ–¥—Ç–≤–µ—Ä–¥–∏ —á—Ç–æ –ø—Ä–∏—à–ª—ë—à—å. –ú–æ–∂–µ—à—å –∑–∞–¥–∞—Ç—å –û–î–ò–ù —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å."
        }
    
    if current_is_rejection and total_rejections == 1:
        return {
            "action": "CONTINUE",
            "allow_questions": True,
            "reason": "first_call_rejection",
            "instruction": "–ö–ª–∏–µ–Ω—Ç –æ—Ç–∫–∞–∑–∞–ª—Å—è –æ—Ç —Å–æ–∑–≤–æ–Ω–∞. –°–ø–æ–∫–æ–π–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–π –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—é. –°–ø—Ä–æ—Å–∏ –ø—Ä–æ –±—é–¥–∂–µ—Ç –µ—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ–º."
        }
    

    # –Ø–í–ù–û–ï –ü–†–ï–î–õ–û–ñ–ï–ù–ò–ï –°–û–ó–í–û–ù–ê –ø–æ—Å–ª–µ 4 —Å–æ–æ–±—â–µ–Ω–∏–π
    if stats["user_messages"] >= 4 and not stats["call_offered"]:
        return {
            "action": "PROPOSE_CALL",
            "allow_questions": True,
            "reason": "enough_qualification",
            "instruction": "–£–∂–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–æ–æ–±—â–∞–ª–∏—Å—å. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ø—Ä–µ–¥–ª–æ–∂–∏ —Å–æ–∑–≤–æ–Ω: –î–∞–≤–∞–π—Ç–µ —Å–æ–∑–≤–æ–Ω–∏–º—Å—è –Ω–∞ 15 –º–∏–Ω—É—Ç ‚Äî –ø–æ–∫–∞–∂—É –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ–¥ –≤–∞—à –∑–∞–ø—Ä–æ—Å. –ö–æ–≥–¥–∞ —É–¥–æ–±–Ω–µ–µ?"
        }
    if stats["call_offered"]:
        return {
            "action": "CONTINUE",
            "allow_questions": True,
            "reason": "normal_after_call_offer",
            "instruction": "–ü—Ä–æ–¥–æ–ª–∂–∞–π –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—é. –£–∑–Ω–∞–π —á—Ç–æ –Ω–µ –≤—ã—è—Å–Ω–µ–Ω–æ: –±—é–¥–∂–µ—Ç, —Å–ø–æ—Å–æ–± –æ–ø–ª–∞—Ç—ã, —Å—Ä–æ–∫–∏. –û–¥–∏–Ω –≤–æ–ø—Ä–æ—Å."
        }
    else:
        return {
            "action": "QUALIFY_OR_CALL",
            "allow_questions": True,
            "reason": "normal",
            "instruction": "–ï—Å–ª–∏ –∑–Ω–∞–µ–º —Ü–µ–ª—å+–ª–æ–∫–∞—Ü–∏—é+—Å–ø–æ—Å–æ–± –æ–ø–ª–∞—Ç—ã ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏ —Å–æ–∑–≤–æ–Ω –Ω–∞ 15 –º–∏–Ω—É—Ç. –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî –∑–∞–¥–∞–π —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å."
        }


def generate_response(history: list, last_message: str, action: dict, client_name: str = "–ö–ª–∏–µ–Ω—Ç") -> str:
    config = get_model_config()
    
    question_instruction = "–í–ê–ñ–ù–û: –ù–ï –∑–∞–¥–∞–≤–∞–π –≤–æ–ø—Ä–æ—Å–æ–≤. –ù–∏–∫–∞–∫–∏—Ö. –ù–∏ –æ–¥–Ω–æ–≥–æ –∑–Ω–∞–∫–∞ '?'." if not action['allow_questions'] else "–ú–æ–∂–µ—à—å –∑–∞–¥–∞—Ç—å –æ–¥–∏–Ω –≤–æ–ø—Ä–æ—Å –≤ –∫–æ–Ω—Ü–µ."
    
    task_prompt = f"""
–ó–ê–î–ê–ß–ê: {action['instruction']}

{question_instruction}

–ù–∞–ø–∏—à–∏ –æ—Ç–≤–µ—Ç –°–æ—Ñ–∏–∏ (1-3 —Å—Ç—Ä–æ–∫–∏):
"""
    
    if config["use_responses_api"]:
        messages = []
        for msg in history:
            messages.append({"role": msg.get("role"), "content": msg.get("content", "")})
        messages.append({"role": "user", "content": last_message})
        messages.append({"role": "user", "content": task_prompt})
        
        request_params = {
            "model": config["model"],
            "instructions": get_system_prompt(client_name),
            "input": messages,
            "text": {"verbosity": "low"},
        }
        if config.get("reasoning"):
            request_params["reasoning"] = config["reasoning"]
        
        response = client.responses.create(**request_params)
        text = response.output_text.strip()
        text = response.output_text.strip()
    else:
        dialog_lines = []
        for msg in history[-10:]:
            role = "–ö–ª–∏–µ–Ω—Ç" if msg.get("role") == "user" else "–°–æ—Ñ–∏—è"
            dialog_lines.append(f"{role}: {msg.get('content', '')}")
        dialog_lines.append(f"–ö–ª–∏–µ–Ω—Ç: {last_message}")
        dialog_text = "\n".join(dialog_lines)
        
        prompt = f"{SYSTEM_PROMPT}\n\n–ò–ú–Ø –ö–õ–ò–ï–ù–¢–ê: {client_name}\n\n–î–ò–ê–õ–û–ì:\n{dialog_text}\n\n{task_prompt}"
        
        response = client.chat.completions.create(
            model=config["model"],
            messages=[{"role": "user", "content": prompt}],
            temperature=config.get("temperature", 0.4),
            max_tokens=config["max_tokens"]
        )
        text = response.choices[0].message.content.strip()
    
    text = re.sub(r'^["\']|["\']$', '', text)
    text = re.sub(r'^–°–æ—Ñ–∏—è:\s*', '', text)
    
    if not action["allow_questions"] and has_question(text):
        text = remove_question(text)
        if not text.strip():
            text = "–ü–æ–Ω—è–ª–∞, —Å–µ–π—á–∞—Å –ø—Ä–∏—à–ª—é 2-3 –≤–∞—Ä–∏–∞–Ω—Ç–∞ –ø–æ–¥ –≤–∞—à –∑–∞–ø—Ä–æ—Å üôÇ"
    
    return text


def process_message(history: list, user_message: str, client_name: str = "–ö–ª–∏–µ–Ω—Ç") -> tuple[str, dict]:
    stats = analyze_history(history)
    action = decide_action(stats, user_message)
    response = generate_response(history, user_message, action, client_name)
    
    config = get_model_config()
    debug = {
        "stats": stats,
        "action": action["action"],
        "reason": action["reason"],
        "allow_questions": action["allow_questions"],
        "response_has_question": has_question(response),
        "model_mode": MODEL_MODE,
        "model": config["model"],
        "reasoning": config.get("reasoning") is not None
    }
    
    return response, debug


def get_current_model_info() -> str:
    config = get_model_config()
    reasoning_str = "—Å reasoning xhigh" if config.get("reasoning") else "–±–µ–∑ reasoning"
    return f"{config['model']} ({reasoning_str})"
